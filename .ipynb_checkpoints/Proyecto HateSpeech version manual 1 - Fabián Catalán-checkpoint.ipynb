{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar regresión Logistica, random forest, extra* -> red neuronal-> traducir textos a español.[REPETIR EN ESPAÑOL.]\n",
    "\n",
    "> [ HIPÓTESIS ] La traducción afecta al rendimiento del clasificador?\n",
    "\n",
    "Usar modelo transformer -> ingles a español **Tutorial 7**.\n",
    "\n",
    "\n",
    "## 8 de enero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basado en Automated Hate Speech Detection and the Problem of Offensive Language\n",
    "\n",
    "[https://data.world/thomasrdavidson/hate-speech-and-offensive-language](https://data.world/thomasrdavidson/hate-speech-and-offensive-language)\n",
    "\n",
    "Disclaimer WARNING: The data, lexicons, and notebooks all contain content that is racist, sexist, homophobic, and offensive in many other ways.\n",
    "\n",
    "### Data Guide\n",
    "\n",
    "The data are stored as a CSV, each data file contains 5 columns:\n",
    "\n",
    "**count** = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "\n",
    "**hate_speech** = number of CF users who judged the tweet to be hate speech.\n",
    "\n",
    "**offensive_language** = number of CF users who judged the tweet to be offensive.\n",
    "\n",
    "**neither** = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "\n",
    "**class** = class label for majority of CF users.\n",
    "0 - hate speech,\n",
    "1 - offensive language,\n",
    "2 - neither\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5                                                  6\n",
       "1  3  0  0  3  2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "2  3  0  3  0  1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "3  3  0  3  0  1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "4  3  0  2  1  1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "5  6  0  6  0  1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#abrir el dataset\n",
    "d = pd.read_csv(\"hate1.csv\",header=None)\n",
    "#Eliminamos 1° columna y fila innecesarias\n",
    "if len(d.columns)> 6:\n",
    "    d = d.drop(d.columns[0], 1)\n",
    "    d = d.iloc[1:]\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 1 to 24783\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   1       24783 non-null  object\n",
      " 1   2       24783 non-null  object\n",
      " 2   3       24783 non-null  object\n",
      " 3   4       24783 non-null  object\n",
      " 4   5       24783 non-null  object\n",
      " 5   6       24783 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "d.info() # database no nulo y balanceado, en primera instancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cambiamos de posición la columna que clasifica el mensaje al final y reetiquetamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neiter</th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24783</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count hate_speech offensive_language neiter  \\\n",
       "1         3           0                  0      3   \n",
       "2         3           0                  3      0   \n",
       "3         3           0                  3      0   \n",
       "4         3           0                  2      1   \n",
       "5         6           0                  6      0   \n",
       "...     ...         ...                ...    ...   \n",
       "24779     3           0                  2      1   \n",
       "24780     3           0                  1      2   \n",
       "24781     3           0                  3      0   \n",
       "24782     6           0                  6      0   \n",
       "24783     3           0                  0      3   \n",
       "\n",
       "                                                 message class  \n",
       "1      !!! RT @mayasolovely: As a woman you shouldn't...     2  \n",
       "2      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     1  \n",
       "3      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     1  \n",
       "4      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     1  \n",
       "5      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     1  \n",
       "...                                                  ...   ...  \n",
       "24779  you's a muthaf***in lie &#8220;@LifeAsKing: @2...     1  \n",
       "24780  you've gone and broke the wrong heart baby, an...     2  \n",
       "24781  young buck wanna eat!!.. dat nigguh like I ain...     1  \n",
       "24782              youu got wild bitches tellin you lies     1  \n",
       "24783  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...     2  \n",
       "\n",
       "[24783 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d[[1,2,3,4,6,5]]\n",
    "d.columns=['count', 'hate_speech', 'offensive_language', 'neiter', 'message', 'class']\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contamos las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_classes = d['class'].value_counts()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento léxico  con N-gramas (estadístico)\n",
    "\n",
    "> **spacy_tokenizer** generará un vector de palabras dividido\n",
    "\n",
    "> **bow_vector** vectorizará las palabras de a dos (N-gramos) según su relevancia\n",
    "\n",
    "> **tfidf_vector** transforma los textos en vectores para tener los pesos TF-IDF de cada palabra en cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words=\"\"\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function spacy_tokenizer at 0x7f7e040d5ca0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d['message'] # tweets \n",
    "y = d['class']   # clasificación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .45, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x7f7e040d5ca0>)),\n",
       "                ('regression-ML', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression(solver='lbfgs', max_iter=1000) # parámetros para evitar errores de iteración\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('preprocessing', bow_vector),\n",
    "                 ('regression-ML', modelLR)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación del modelo\n",
    "\n",
    "Podemos evaluar el rendimiento de nuestro modelo usando el módulo de métricas de scikit-learn. Ahora que hemos entrenado nuestro modelo, pondremos nuestros datos de prueba a disposición para hacer predicciones. Luego usaremos varias funciones del módulo de métricas para ver la exactitud, precisión y recall de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' '2' ... '2' '1' '1']\n",
      "Logistic Regression Accuracy: 0.8945575181565498\n",
      "Logistic Regression Precision: 0.8945575181565498\n",
      "Logistic Regression Recall: 0.8945575181565498\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "print(predicted)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted, average='micro'))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 137  413   64]\n",
      " [ 143 8257  258]\n",
      " [  20  278 1583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.22      0.30       614\n",
      "           1       0.92      0.95      0.94      8658\n",
      "           2       0.83      0.84      0.84      1881\n",
      "\n",
      "    accuracy                           0.89     11153\n",
      "   macro avg       0.74      0.67      0.69     11153\n",
      "weighted avg       0.88      0.89      0.89     11153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predicted)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printNMostInformative(vectorizer, model, N):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(model.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 best: \n",
      "(-1.2172576985379937, 'bird')\n",
      "(-0.9325509360293304, 'imma')\n",
      "(-0.813715662921115, 'remember')\n",
      "(-0.7968451014006322, 'ho')\n",
      "(-0.7921762177220638, 'birds')\n",
      "(-0.7896245992880705, 'charlie')\n",
      "(-0.7642825242895863, 'crazy')\n",
      "(-0.7459865448355021, 'its')\n",
      "(-0.6921438986726948, 'yellow')\n",
      "(-0.6878548898299696, 'weed')\n",
      "(-0.6743548047900063, 'woman')\n",
      "(-0.6622771136407989, 'girls')\n",
      "(-0.6438012085947404, '@ivanrabago')\n",
      "(-0.6429506789381668, 'til')\n",
      "(-0.6415810436620708, 'love')\n",
      "(-0.6405212992654807, 'red')\n",
      "(-0.6335319750614081, 'after')\n",
      "(-0.6314268450587154, 'hard')\n",
      "(-0.6309556853832609, 'great')\n",
      "(-0.6185010080275121, 'single')\n",
      "Class 2 best: \n",
      "(2.4334250390032315, 'faggot')\n",
      "(2.238845917901955, 'nigger')\n",
      "(2.170525625455344, 'fag')\n",
      "(2.1503749693819487, 'niggers')\n",
      "(2.0609249182638956, 'nigga')\n",
      "(1.9196117835156117, 'faggots')\n",
      "(1.8071335056339664, 'fags')\n",
      "(1.7293837046719647, 'dyke')\n",
      "(1.5888244033064869, 'fuck')\n",
      "(1.5737963098636247, 'queer')\n",
      "(1.5713616724127986, 'white')\n",
      "(1.5448913886110813, 'coon')\n",
      "(1.4168377223109745, 'niggas')\n",
      "(1.3929865036164968, 'queers')\n",
      "(1.3705599069146226, 'chink')\n",
      "(1.3567810145288817, 'fucking')\n",
      "(1.338972587567473, 'gook')\n",
      "(1.3269691296193933, 'wetback')\n",
      "(1.2867719700499798, 'race')\n",
      "(1.2705777960514004, 'ass')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "printNMostInformative(bow_vector, modelLR, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
